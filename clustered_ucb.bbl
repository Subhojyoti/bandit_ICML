\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal \& Goyal(2011)Agrawal and Goyal]{agrawal2011analysis}
Agrawal, Shipra and Goyal, Navin.
\newblock Analysis of thompson sampling for the multi-armed bandit problem.
\newblock \emph{arXiv preprint arXiv:1111.1797}, 2011.

\bibitem[Audibert \& Bubeck(2009)Audibert and Bubeck]{audibert2009minimax}
Audibert, Jean-Yves and Bubeck, S{\'e}bastien.
\newblock Minimax policies for adversarial and stochastic bandits.
\newblock In \emph{COLT}, pp.\  217--226, 2009.

\bibitem[Audibert et~al.(2009)Audibert, Munos, and
  Szepesv{\'a}ri]{audibert2009exploration}
Audibert, Jean-Yves, Munos, R{\'e}mi, and Szepesv{\'a}ri, Csaba.
\newblock Exploration--exploitation tradeoff using variance estimates in
  multi-armed bandits.
\newblock \emph{Theoretical Computer Science}, 410\penalty0 (19):\penalty0
  1876--1902, 2009.

\bibitem[Auer(2002)]{auer2002using}
Auer, Peter.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 397--422, 2002.

\bibitem[Auer \& Ortner(2010)Auer and Ortner]{auer2010ucb}
Auer, Peter and Ortner, Ronald.
\newblock Ucb revisited: Improved regret bounds for the stochastic multi-armed
  bandit problem.
\newblock \emph{Periodica Mathematica Hungarica}, 61\penalty0 (1-2):\penalty0
  55--65, 2010.

\bibitem[Auer et~al.(2002{\natexlab{a}})Auer, Cesa-Bianchi, and
  Fischer]{auer2002finite}
Auer, Peter, Cesa-Bianchi, Nicolo, and Fischer, Paul.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 47\penalty0 (2-3):\penalty0 235--256,
  2002{\natexlab{a}}.

\bibitem[Auer et~al.(2002{\natexlab{b}})Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
Auer, Peter, Cesa-Bianchi, Nicolo, Freund, Yoav, and Schapire, Robert~E.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM Journal on Computing}, 32\penalty0 (1):\penalty0 48--77,
  2002{\natexlab{b}}.

\bibitem[Beygelzimer et~al.(2011)Beygelzimer, Langford, Li, Reyzin, and
  Schapire]{beygelzimer2011contextual}
Beygelzimer, Alina, Langford, John, Li, Lihong, Reyzin, Lev, and Schapire,
  Robert~E.
\newblock Contextual bandit algorithms with supervised learning guarantees.
\newblock In \emph{AISTATS}, pp.\  19--26, 2011.

\bibitem[Bubeck et~al.(2009)Bubeck, Munos, and Stoltz]{bubeck2009pure}
Bubeck, S{\'e}bastien, Munos, R{\'e}mi, and Stoltz, Gilles.
\newblock Pure exploration in multi-armed bandits problems.
\newblock In \emph{International conference on Algorithmic learning theory},
  pp.\  23--37. Springer, 2009.

\bibitem[Bubeck et~al.(2011)Bubeck, Munos, and Stoltz]{bubeck2011pure}
Bubeck, S{\'e}bastien, Munos, R{\'e}mi, and Stoltz, Gilles.
\newblock Pure exploration in finitely-armed and continuous-armed bandits.
\newblock \emph{Theoretical Computer Science}, 412\penalty0 (19):\penalty0
  1832--1852, 2011.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, and
  Lugosi]{bubeck2012bandits}
Bubeck, S{\'e}bastien, Cesa-Bianchi, Nicolo, and Lugosi, G{\'a}bor.
\newblock Bandits with heavy tail.
\newblock \emph{arXiv preprint arXiv:1209.1727}, 2012.

\bibitem[Bui et~al.(2012)Bui, Johari, and Mannor]{bui2012clustered}
Bui, Loc, Johari, Ramesh, and Mannor, Shie.
\newblock Clustered bandits.
\newblock \emph{arXiv preprint arXiv:1206.4169}, 2012.

\bibitem[Cappe et~al.(2012)Cappe, Garivier, and Kaufmann]{CapGarKau12}
Cappe, Olivier, Garivier, Aurelien, and Kaufmann, Emilie.
\newblock pymabandits, 2012.
\newblock \url{http://mloss.org/software/view/415/}.

\bibitem[Cesa-Bianchi et~al.(2013)Cesa-Bianchi, Gentile, and
  Zappella]{cesa2013gang}
Cesa-Bianchi, Nicolo, Gentile, Claudio, and Zappella, Giovanni.
\newblock A gang of bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  737--745, 2013.

\bibitem[Even-Dar et~al.(2006)Even-Dar, Mannor, and Mansour]{even2006action}
Even-Dar, Eyal, Mannor, Shie, and Mansour, Yishay.
\newblock Action elimination and stopping conditions for the multi-armed bandit
  and reinforcement learning problems.
\newblock \emph{The Journal of Machine Learning Research}, 7:\penalty0
  1079--1105, 2006.

\bibitem[Friedman et~al.(2001)Friedman, Hastie, and
  Tibshirani]{friedman2001elements}
Friedman, Jerome, Hastie, Trevor, and Tibshirani, Robert.
\newblock \emph{The elements of statistical learning}, volume~1.
\newblock Springer series in statistics Springer, Berlin, 2001.

\bibitem[Garivier \& Capp{\'e}(2011)Garivier and Capp{\'e}]{garivier2011kl}
Garivier, Aur{\'e}lien and Capp{\'e}, Olivier.
\newblock The kl-ucb algorithm for bounded stochastic bandits and beyond.
\newblock \emph{arXiv preprint arXiv:1102.2490}, 2011.

\bibitem[Gentile et~al.(2014)Gentile, Li, and Zappella]{gentile2014online}
Gentile, Claudio, Li, Shuai, and Zappella, Giovanni.
\newblock Online clustering of bandits.
\newblock In \emph{ICML}, pp.\  757--765, 2014.

\bibitem[Honda \& Takemura(2010)Honda and Takemura]{honda2010asymptotically}
Honda, Junya and Takemura, Akimichi.
\newblock An asymptotically optimal bandit algorithm for bounded support
  models.
\newblock In \emph{COLT}, pp.\  67--79. Citeseer, 2010.

\bibitem[Lai \& Robbins(1985)Lai and Robbins]{lai1985asymptotically}
Lai, Tze~Leung and Robbins, Herbert.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock \emph{Advances in applied mathematics}, 6\penalty0 (1):\penalty0
  4--22, 1985.

\bibitem[Langford \& Zhang(2008)Langford and Zhang]{langford2008epoch}
Langford, John and Zhang, Tong.
\newblock The epoch-greedy algorithm for multi-armed bandits with side
  information.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  817--824, 2008.

\bibitem[Lattimore(2015)]{lattimore2015optimally}
Lattimore, Tor.
\newblock Optimally confident ucb: Improved regret for finite-armed bandits.
\newblock \emph{arXiv preprint arXiv:1507.07880}, 2015.

\bibitem[Li et~al.(2010)Li, Chu, Langford, and Schapire]{li2010contextual}
Li, Lihong, Chu, Wei, Langford, John, and Schapire, Robert~E.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In \emph{Proceedings of the 19th international conference on World
  wide web}, pp.\  661--670. ACM, 2010.

\bibitem[Liu \& Tsuruoka(2016)Liu and Tsuruoka]{liu2016modification}
Liu, Yun-Ching and Tsuruoka, Yoshimasa.
\newblock Modification of improved upper confidence bounds for regulating
  exploration in monte-carlo tree search.
\newblock \emph{Theoretical Computer Science}, 2016.

\bibitem[Mannor \& Tsitsiklis(2004)Mannor and Tsitsiklis]{mannor2004sample}
Mannor, Shie and Tsitsiklis, John~N.
\newblock The sample complexity of exploration in the multi-armed bandit
  problem.
\newblock \emph{Journal of Machine Learning Research}, 5\penalty0
  (Jun):\penalty0 623--648, 2004.

\bibitem[Robbins(1952)]{robbins1952some}
Robbins, Herbert.
\newblock Some aspects of the sequential design of experiments.
\newblock In \emph{Herbert Robbins Selected Papers}, pp.\  169--177. Springer,
  1952.

\bibitem[Slivkins(2014)]{slivkins2014contextual}
Slivkins, Aleksandrs.
\newblock Contextual bandits with similarity information.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 2533--2568, 2014.

\bibitem[Thompson(1933)]{thompson1933likelihood}
Thompson, William~R.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, pp.\  285--294, 1933.

\bibitem[Tolpin \& Shimony(2012)Tolpin and Shimony]{tolpin2012mcts}
Tolpin, David and Shimony, Solomon~Eyal.
\newblock Mcts based on simple regret.
\newblock In \emph{AAAI}, 2012.

\end{thebibliography}
